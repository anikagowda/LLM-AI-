{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_FnaF0zfPtd5"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","import os\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHIr-9W-dM2p","outputId":"a9043f00-4fcd-4780-8f55-f26d0a727ec1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oppgglW0mIhI","outputId":"dc7228de-3274-4b98-f687-bfba3b6026e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["'1000151722 (1080×2400)'\n","'1000151722 (1080×2400) (1)'\n","'AI project'\n"," ASS_DL_02.jpg\n","'cb (1).pdf'\n"," cb.pdf\n"," Classroom\n","'Colab Notebooks'\n"," deep_learning\n"," Deep_Learning.ipynb\n"," dip\n","'Document from Anika Gowda (1).pdf'\n","'Document from Anika Gowda (2).pdf'\n","'Document from Anika Gowda.pdf'\n","'Draft_merged (1).gdoc'\n","'Draft_merged (1).pdf'\n"," engg_cutoff_gen.pdf\n"," FEE.jpg\n","'Getting started.pdf'\n"," Hallticket_2021125418_13082021_164518.pdf\n","'II PUC MARKS CARD PRO (1).pdf'\n","'II PUC MARKS CARD PRO (2).pdf'\n","'II PUC MARKS CARD PRO BOARD.pdf'\n","'II PUC MARKS CARD PRO.pdf'\n","'ilovepdf_merged (5).pdf'\n"," inttgfff.pdf\n","'MAMATHA AADHAAR.pdf'\n","'New Doc 2021-02-22 10.37.15.pdf'\n"," NLP\n","'NMAM1980  AADHAAR.pdf'\n"," online_paymentresponse.pdf\n","'PASS BOOK.jpg'\n","'PHOTO (1).jpg'\n","'PHOTO (2).jpg'\n"," PHOTO.jpg\n","'RAKSHIT Technical Seminar Report.pdf'\n","'Rooman Certificate (1).pdf'\n","'Rooman Certificate.pdf'\n"," sample+variance_merged.pdf\n"," Screenshot_2022-12-20-14-05-10-36_e307a3f9df9f380ebaf106e1dc980bb6.jpg\n"," Screenshot_2024-12-30-11-28-31-26_40deb401b9ffe8e1df2f1cc5ba480b12.jpg\n","'Share Root locus.pdf'\n"," SIGN.jpg\n","'SSLC MARKS CARD.jpg'\n"," starting.pdf\n"," Student_AFD_4794791_2942022173747513.pdf\n"," templates-20251014T141403Z-1-001.zip\n","'VLSI 1.pdf'\n","'vlsi 2.pdf'\n"]}],"source":["!ls /content/drive/MyDrive/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mBZySf70dM5v","colab":{"base_uri":"https://localhost:8080/"},"outputId":"309de15a-724f-4ced-aba9-eea42c544249"},"outputs":[{"output_type":"stream","name":"stdout","text":["Folders inside trainingSet:\n","['srk', 'don', 'warrior', 'boss', 'anika']\n"]}],"source":["data_dir = \"/content/drive/MyDrive/AI project/face recognition/3. Cropped_face\" # Replace with the correct path to your data\n","print(\"Folders inside trainingSet:\")\n","print(os.listdir(data_dir))\n","\n"]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Create generator with 20% for validation\n","datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2  # 20% of images will be used for validation\n",")\n","\n","# Training generator (80% of data)\n","training_set = datagen.flow_from_directory(\n","    \"/content/drive/MyDrive/AI project/face recognition/3. Cropped_face\",            # your single folder with all person folders\n","    target_size=(64,64),\n","    batch_size=16,\n","    class_mode='categorical',\n","    subset='training'      # 80% used for training\n",")\n","\n","# Validation generator (20% of data)\n","validation_set = datagen.flow_from_directory(\n","   \"/content/drive/MyDrive/AI project/face recognition/3. Cropped_face\",\n","    target_size=(64,64),\n","    batch_size=16,\n","    class_mode='categorical',\n","    subset='validation'    # 20% used for validation\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bpq0VYdqwqr_","outputId":"51ec5eb0-d153-42fd-95d4-a14da98e75f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2434 images belonging to 5 classes.\n","Found 606 images belonging to 5 classes.\n"]}]},{"cell_type":"code","source":["cnn = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=[64, 64, 3]),\n","    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n","\n","    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n","    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n","\n","    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n","    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n","\n","\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(5, activation='softmax')\n","])\n","\n","\n","cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","\n","cnn.fit(x=training_set, validation_data=validation_set, epochs=5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EARbX24iu5Ly","outputId":"1e681d9e-bace-4ec8-8892-be5a947b0ecd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 113ms/step - accuracy: 0.4323 - loss: 1.3483 - val_accuracy: 0.6881 - val_loss: 1.2547\n","Epoch 2/5\n","\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 113ms/step - accuracy: 0.9503 - loss: 0.1510 - val_accuracy: 0.7409 - val_loss: 1.0389\n","Epoch 3/5\n","\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 98ms/step - accuracy: 0.9860 - loss: 0.0509 - val_accuracy: 0.5974 - val_loss: 1.6224\n","Epoch 4/5\n","\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 98ms/step - accuracy: 0.9893 - loss: 0.0347 - val_accuracy: 0.6931 - val_loss: 0.9692\n","Epoch 5/5\n","\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 98ms/step - accuracy: 0.9934 - loss: 0.0235 - val_accuracy: 0.6452 - val_loss: 1.4452\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7e633ad15370>"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.preprocessing import image\n","\n","# Load and preprocess image\n","test_image = image.load_img('/content/drive/MyDrive/AI project/face recognition/3. Cropped_face/boss/a_frame0.jpg',\n","                            target_size=(64, 64))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis=0)\n","test_image = test_image / 255.0  # normalize like training set\n","\n","# Predict\n","result = cnn.predict(test_image)\n","\n","# Get class labels\n","class_labels = list(training_set.class_indices.keys())\n","\n","# Find the predicted label\n","predicted_class_index = np.argmax(result)\n","prediction = class_labels[predicted_class_index]\n","\n","print(\"Predicted face:\", prediction)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pArmgyEOwR2f","outputId":"734a4465-20e2-42f7-a137-45bbfa3b86e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Predicted face: warrior\n"]}]},{"cell_type":"code","source":["0.8764 - loss: 0.3594 - val_accuracy: 0.6188 - val_loss: 1.4024"],"metadata":{"id":"WqTFsVVpeqYn"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}